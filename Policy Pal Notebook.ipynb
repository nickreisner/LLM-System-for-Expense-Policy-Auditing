{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDEeIuQCYJDH"
   },
   "source": [
    "# README\n",
    "## Notebook Instructions\n",
    "\n",
    "1. (In Section 1) Insert your Together.AI API key.\n",
    "2. Make sure that the files 'Stanford_Expenses Pre-Processed.json' and 'Stanford University Expense Policy With Labeled Sections.jsonl' are in the local directory.\n",
    "3. Add a pdf file of an expense receipt to the local directory. The expense must be of one of the following categories: \"Airfare\", \"Lodging\", \"Ground Transportation\", \"Meals\", \"Other Reimbursable Business Expenses\", \"Employee Gifts\", \"Business Meals\", and \"Travel Meals\".\n",
    "4. (In Section 7) Insert the filepath of the receipt's pdf.\n",
    "5. Fill in the user information in Section 7: status and date.\n",
    "5. Run all cells except for those in Section 6.\n",
    "6. Wait for the last cell to run for the main execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGvTsL6NSSKh"
   },
   "source": [
    "# SECTION 1: Load client and packages\n",
    "[Action Item] Insert your Together.AI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kn38XLFuSPZZ",
    "outputId": "22072883-1f36-4e34-fb12-6a7a82ab6325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: together in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.10/dist-packages (from together) (3.11.9)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from together) (8.1.7)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from together) (0.2.0)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.10/dist-packages (from together) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from together) (1.26.4)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from together) (10.4.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from together) (17.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from together) (2.10.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from together) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.10/dist-packages (from together) (13.9.4)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.10/dist-packages (from together) (4.66.6)\n",
      "Requirement already satisfied: typer<0.14,>=0.9 in /usr/local/lib/python3.10/dist-packages (from together) (0.13.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.14,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install together\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YxBIuC5GBb5"
   },
   "outputs": [],
   "source": [
    "from together import Together\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional, List\n",
    "import sys\n",
    "import PyPDF2\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6R-lI51GSde9"
   },
   "source": [
    "## [Action Item] Insert your together API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iK_MO1ppSMpi"
   },
   "outputs": [],
   "source": [
    "client = Together(api_key=FILL HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZAUkDgrHsaG"
   },
   "source": [
    "# SECTION 2: Loading files (Policy and Receipts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0b1rC0iGqDe"
   },
   "outputs": [],
   "source": [
    "# Function to read a JSONL file\n",
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCFXy5nVX6iK"
   },
   "outputs": [],
   "source": [
    "def extract_receipt_info(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract information from a receipt PDF and structure it into a JSON format.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF receipt\n",
    "\n",
    "    Returns:\n",
    "        dict: Structured receipt information\n",
    "    \"\"\"\n",
    "    # Extract text from PDF\n",
    "    def extract_text_from_pdf(file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "    # Get raw text from receipt\n",
    "    receipt_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    # Instructions\n",
    "    You are an AI assistant helping to extract information from receipts into a structured JSON format.\n",
    "    Analyze the receipt text and create a JSON object with relevant information.\n",
    "\n",
    "    The structure should be:\n",
    "    {{\n",
    "      \"receipt\": {{\n",
    "        \"general_information\": {{\n",
    "          \"receipt_id\": (if available),\n",
    "          \"receipt_date\": (date in any format found),\n",
    "          \"receipt_time\": (if available),\n",
    "          \"vendor_name\": (business name),\n",
    "          \"vendor_address\": (if available),\n",
    "          \"transaction_type\": (if specified),\n",
    "          \"payment_method\": (if available),\n",
    "          \"currency\": (default to \"USD\" if not specified)\n",
    "        }},\n",
    "        \"expense_details\": {{\n",
    "          // For standard receipts with subtotal/tax/tip:\n",
    "          \"total_amount\": (total including tax and tip),\n",
    "          \"subtotal\": (before tax and tip),\n",
    "          \"taxes\": (if itemized),\n",
    "          \"discounts\": (if any),\n",
    "          \"tip\": (if included),\n",
    "            // OR for transportation:\n",
    "            // Include any specific fees, charges, or fare details\n",
    "          }}\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "\n",
    "    Receipt Text:\n",
    "    {receipt_text}\n",
    "\n",
    "    Important:\n",
    "    - Include only fields where information is available\n",
    "    - Format numbers as numbers, not strings\n",
    "    - Format dates and times as strings\n",
    "    - Use consistent formatting\n",
    "    - Include category-specific details based on receipt type\n",
    "    - Maintain proper JSON structure\n",
    "\n",
    "    Return only valid JSON without any additional text or explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "\n",
    "    # Extract JSON from response\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    # Find JSON using regex\n",
    "    json_match = re.search(r'({[\\s\\S]*})', output)\n",
    "    if json_match:\n",
    "        try:\n",
    "            return json.loads(json_match.group())\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: Found JSON-like structure but couldn't parse\")\n",
    "            return {}\n",
    "    else:\n",
    "        print(\"Error: Couldn't find JSON in response\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0T5u4NwzHdJZ"
   },
   "outputs": [],
   "source": [
    "extracted_receipt_json =  {\n",
    "              \"receipt\": {\n",
    "                \"general_information\": {\n",
    "                  \"receipt_id\": \"12345\",\n",
    "                  \"receipt_date\": \"10/09/2024\",\n",
    "                  \"receipt_time\":\"9:23 PM\",\n",
    "                  \"vendor_name\": \"Shake Shack\",\n",
    "                  \"vendor_address\": \"459 Lagunita Dr\",\n",
    "                  \"transaction_type\": \"Sale\",\n",
    "                  \"payment_method\": \"VISA 1234\",\n",
    "                  \"currency\": \"USD\"\n",
    "                },\n",
    "                \"expense_details\": {\n",
    "                  \"total_amount\": 38.88,\n",
    "                  \"subtotal\": 32,\n",
    "                  \"taxes\": 2.88,\n",
    "                  \"discounts\": 0,\n",
    "                  \"tip\": 4,\n",
    "                  \"category_specific_details\": {\n",
    "                    \"meals\": {\n",
    "                      \"location\": \"Stanford CA\",\n",
    "                      \"items\": {\n",
    "                          \"1 Burger\": 12,\n",
    "                          \"1 Wine\": 10,\n",
    "                          \"1 Fries\": 10\n",
    "                      }\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4cQbX_jHgQZ",
    "outputId": "abfbbf20-8db4-4677-e2b4-1efb9e5f26ea"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nextracted_receipt_json =  {\\n              \"receipt\": {\\n                \"general_information\": {\\n                  \"receipt_date\": \"December 2 2024\",\\n                  \"vendor_name\": \"Uber\",\\n                  \"payment_method\": \"VISA 9130\",\\n                  \"currency\": \"USD\",\\n                  \"from\": \"SFO International Airport\",\\n                  \"to\": \"1035 Campus Drive, Stanford CA 94305\",\\n                },\\n                \"expense_details\": {\\n                  \"Trip fair\": 37.56,\\n                  \"Booking Fee\": 11.61,\\n                  \"SFO Airport Surcharge\": 5.50,\\n                  \"Access for All Fee\": 0.10,\\n                  \"CA Driver Benefits\": 0.32,\\n                  \"Tip\": 5.00,\\n                  \"Promotion\": -2.75,\\n                  \"Total\": 57.34\\n                }\\n              }\\n            }\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "extracted_receipt_json =  {\n",
    "              \"receipt\": {\n",
    "                \"general_information\": {\n",
    "                  \"receipt_date\": \"December 2 2024\",\n",
    "                  \"vendor_name\": \"Uber\",\n",
    "                  \"payment_method\": \"VISA 9130\",\n",
    "                  \"currency\": \"USD\",\n",
    "                  \"from\": \"SFO International Airport\",\n",
    "                  \"to\": \"1035 Campus Drive, Stanford CA 94305\",\n",
    "                },\n",
    "                \"expense_details\": {\n",
    "                  \"Trip fair\": 37.56,\n",
    "                  \"Booking Fee\": 11.61,\n",
    "                  \"SFO Airport Surcharge\": 5.50,\n",
    "                  \"Access for All Fee\": 0.10,\n",
    "                  \"CA Driver Benefits\": 0.32,\n",
    "                  \"Tip\": 5.00,\n",
    "                  \"Promotion\": -2.75,\n",
    "                  \"Total\": 57.34\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iGPExLtHnvS"
   },
   "source": [
    "# SECTION 3: Pre Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXySAzVgHhJT"
   },
   "outputs": [],
   "source": [
    "# Function to summarize content using an LLM\n",
    "def summarize_content(content):\n",
    "    prompt = f\"\"\"\n",
    "    You are given a segment of an expense policy. Your task is to produce a concise summary that highlights which types of expenses this section applies to, along with the conditions or contexts in which it is relevant. The summary should:\n",
    "\n",
    "    1. Identify the categories of expenses covered (e.g., travel, lodging, meals, conference fees, equipment).\n",
    "    2. Highlight any roles or stakeholders mentioned (e.g., employees, faculty, students, guests).\n",
    "    3. Mention any conditions or constraints (e.g., domestic vs. international travel, allowable amounts, required documentation).\n",
    "    4. Avoid irrelevant details and focus on information that would help determine whether this section is applicable to a given expense.\n",
    "    5. Be written as a standalone summary, without referencing the instruction text.\n",
    "    Policy:\n",
    "    {content}\n",
    "\n",
    "    Summary:\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct-Turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irTDf5JfH8IO"
   },
   "outputs": [],
   "source": [
    "# Function to analyze content and structure it into individual atomic clauses\n",
    "def analyze_content_to_clauses(content):\n",
    "    prompt = f\"\"\"\n",
    "        Analyze the following policy content and extract individual atomic clauses. Each clause should correspond to a specific rule that can be applied to evaluating whether an expense is valid or not.\n",
    "        Format the output as a list of rules.\n",
    "        For example:\n",
    "        [\\\"1. An expense must have a receipt\\\",\\\"2. Travel meals should not be more than $50 USD.\\\"]\n",
    "\n",
    "        Content to analyze:\n",
    "        {content}\n",
    "        Rules:\n",
    "        \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct-Turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbM5om09WThS"
   },
   "outputs": [],
   "source": [
    "def label_section(policy, section_path, organization):\n",
    "    \"\"\"\n",
    "    Break policy sections into logically coherent clauses.\n",
    "    \"\"\"\n",
    "    # Convert section path to policy tree path\n",
    "    path_parts = [part.strip() for part in section_path.split(\">\")]\n",
    "\n",
    "    # Get the content from the policy tree using unpacked arguments\n",
    "    section_content = policy_tree.get_section(*path_parts).raw_content\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    # Instructions\n",
    "    You are helping with expense auditing for {organization}.\n",
    "    The goal is to pre-process the expense policy so that an automated system can later check if a receipt complies with the policy.\n",
    "\n",
    "    For the following section break it up into sentences or logically-connected sentences and label each as one of the following:\n",
    "\n",
    "    1. \"Need user detail to determine if valid expense\"\n",
    "       Use this label when:\n",
    "       - The clause contains words like \"must\", \"required\", \"only\", \"should\" that create a requirement\n",
    "       - The system needs specific information to verify if the requirement was met\n",
    "       - The requirement could make the expense invalid if not met\n",
    "\n",
    "       Examples:\n",
    "       - \"Must adhere to policy X\" -> Need user detail (system needs to verify adherence)\n",
    "       - \"Only economy flights allowed\" -> Need user detail (system needs flight class)\n",
    "       - \"Should be used when X condition applies\" -> Need user detail (system needs to verify condition)\n",
    "\n",
    "    2. \"Required Action\"\n",
    "       Use this label when the clause requires specific additional steps like:\n",
    "       - Submit extra documentation\n",
    "       - Get approvals\n",
    "       - Complete forms\n",
    "       - Provide comparisons\n",
    "\n",
    "       Examples:\n",
    "       - \"Upload comparative quotes\"\n",
    "       - \"Attach receipt copies\"\n",
    "       - \"Get manager signature\"\n",
    "\n",
    "    3. \"Keep In Mind\"\n",
    "       Use this label ONLY for:\n",
    "       - Pure information with no requirements\n",
    "       - Process descriptions that don't affect validity\n",
    "       - Helpful context that doesn't create any rules\n",
    "\n",
    "       Examples:\n",
    "       - \"Reimbursements are processed weekly\"\n",
    "       - \"The university has preferred vendors\"\n",
    "       - \"You can create a travel account\"\n",
    "\n",
    "    Section:\n",
    "    {section_content}\n",
    "\n",
    "    Key points:\n",
    "    - If the clause uses words like \"must\", \"required\", \"should\", \"only\" - it's usually \"Need user detail\"\n",
    "    - If it requires new documents/approvals or the user - it's \"Required Action\"\n",
    "    - If it's purely informational with no requirements - it's \"Keep In Mind\"\n",
    "\n",
    "    Analyze the policy section and return a JSON array where each element has two fields:\n",
    "    - \"text\": The exact sentence or logically-connected group of sentences without any modifications, numbering, or formatting changes\n",
    "    - \"label\": One of these three exact strings:\n",
    "        - \"Need user detail to determine if valid expense\"\n",
    "        - \"Required Action\"\n",
    "        - \"Keep In Mind\"\n",
    "\n",
    "    Return nothing by the JSON array, with no additional text what so ever.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    # Find the JSON array in the response using regex\n",
    "    array_match = re.search(r'\\[\\s*{.*}\\s*\\]', output, re.DOTALL)\n",
    "    if array_match:\n",
    "        try:\n",
    "            return json.loads(array_match.group())\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: Found array-like structure but couldn't parse as JSON\")\n",
    "            return []\n",
    "    else:\n",
    "        print(\"Error: Couldn't find JSON array in response\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZgiseN-S6UP"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PolicyNode:\n",
    "    title: str\n",
    "    raw_content: Optional[str] = None\n",
    "    content_labels: Optional[List[Dict]] = None\n",
    "    url: Optional[str] = None\n",
    "    qualifying_questions: Optional[List[dict]] = None\n",
    "    children: Dict[str, 'PolicyNode'] = field(default_factory=dict)\n",
    "\n",
    "class PolicyTree:\n",
    "    def __init__(self, policy_name: str = \"Policy\", organization: str = \"\"):\n",
    "        self.root = PolicyNode(policy_name)\n",
    "        self.organization = organization\n",
    "\n",
    "    def add_policy_item(self, item: dict):\n",
    "        \"\"\"Add a policy item to the tree structure\"\"\"\n",
    "        doc_title = item['document_title']\n",
    "        section_path = item['section_title'].split(' > ') if item['section_title'] else []\n",
    "        raw_content = item['content']\n",
    "        url = item['url']\n",
    "\n",
    "        # Get pre-processed data from the item\n",
    "        qualifying_questions = item.get('qualifying_questions', None)\n",
    "        content_labels = item.get('labels', None)  # Get existing labels if present\n",
    "\n",
    "        # Start from the root node\n",
    "        current_node = self.root\n",
    "\n",
    "        # Add document level if it doesn't exist\n",
    "        if doc_title not in current_node.children:\n",
    "            current_node.children[doc_title] = PolicyNode(doc_title)\n",
    "\n",
    "        # Move to document node\n",
    "        current_node = current_node.children[doc_title]\n",
    "\n",
    "        # If no section path, update document content\n",
    "        if not section_path:\n",
    "            current_node.raw_content = raw_content\n",
    "            current_node.qualifying_questions = qualifying_questions\n",
    "            current_node.url = url\n",
    "            current_node.content_labels = content_labels  # Set existing labels\n",
    "            return\n",
    "\n",
    "        # Navigate/create the section path\n",
    "        for section in section_path:\n",
    "            if section not in current_node.children:\n",
    "                current_node.children[section] = PolicyNode(section)\n",
    "            current_node = current_node.children[section]\n",
    "\n",
    "        # Update the content at final node\n",
    "        current_node.raw_content = raw_content\n",
    "        current_node.qualifying_questions = qualifying_questions\n",
    "        current_node.url = url\n",
    "        current_node.content_labels = content_labels  # Set existing labels\n",
    "\n",
    "    def label_all_sections(self):\n",
    "        \"\"\"\n",
    "        Find and label all sections in the tree that have content.\n",
    "        \"\"\"\n",
    "        def traverse_and_label(node, path=[]):\n",
    "            if node.raw_content and not node.content_labels:  # Only label if no labels exist\n",
    "                path_str = \" > \".join(path) if path else path[0]\n",
    "                node.content_labels = label_section(self, path_str, self.organization)\n",
    "\n",
    "            for child_title, child_node in node.children.items():\n",
    "                traverse_and_label(child_node, path + [child_title] if path else [child_title])\n",
    "\n",
    "        traverse_and_label(self.root)\n",
    "\n",
    "    def load_from_jsonl(self, items: List[dict]):\n",
    "        \"\"\"Load multiple policy items\"\"\"\n",
    "        for item in items:\n",
    "            self.add_policy_item(item)\n",
    "\n",
    "    def get_section(self, *path) -> Optional[PolicyNode]:\n",
    "        \"\"\"Get a specific section by path\"\"\"\n",
    "        current = self.root\n",
    "        for section in path:\n",
    "            if section not in current.children:\n",
    "                return None\n",
    "            current = current.children[section]\n",
    "        return current\n",
    "\n",
    "    def get_children_at_level(self, *path) -> List[str]:\n",
    "        \"\"\"Get all subsection titles at a specific level\"\"\"\n",
    "        node = self.get_section(*path)\n",
    "        if node:\n",
    "            return list(node.children.keys())\n",
    "        return []\n",
    "\n",
    "    def get_content(self, *path) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Get content at a specific path\n",
    "\n",
    "        Returns:\n",
    "            - None if the path doesn't exist or is root\n",
    "            - raw_content if path exists\n",
    "        \"\"\"\n",
    "        if not path:  # Don't return content for root\n",
    "            return None\n",
    "        node = self.get_section(*path)\n",
    "        return node.raw_content if node else None\n",
    "\n",
    "    def get_url(self, *path) -> Optional[str]:\n",
    "        \"\"\"Get URL at a specific path\"\"\"\n",
    "        node = self.get_section(*path)\n",
    "        return node.url if node else None\n",
    "\n",
    "    def get_labels(self, *path) -> Optional[List[Dict]]:\n",
    "        \"\"\"Get content labels for a specific path\"\"\"\n",
    "        node = self.get_section(*path)\n",
    "        return node.content_labels if node else None\n",
    "\n",
    "    def generate_all_questions(self, question_generator_func):\n",
    "        \"\"\"\n",
    "        Generate questions for all nodes in the tree, level by level.\n",
    "        Parent questions are passed to children for context.\n",
    "        \"\"\"\n",
    "        def format_questions_for_prompt(questions_list):\n",
    "            \"\"\"Format questions into the expected string format for the prompt\"\"\"\n",
    "            formatted = []\n",
    "            for q in questions_list:\n",
    "                formatted.append(f\"Q: {q['question']}\")\n",
    "                formatted.append(f\"A: {q['answer']}\")\n",
    "            return \"\\n\".join(formatted)\n",
    "\n",
    "        def process_level(current_path=None):\n",
    "            if current_path is None:\n",
    "                current_path = []\n",
    "\n",
    "            current_node = self.get_section(*current_path) if current_path else self.root\n",
    "            children = self.get_children_at_level(*current_path)\n",
    "\n",
    "            # Get accumulated questions from the path\n",
    "            accumulated_questions = []\n",
    "            path_cursor = self.root\n",
    "            for section in current_path:\n",
    "                path_cursor = path_cursor.children[section]\n",
    "                if path_cursor.qualifying_questions:\n",
    "                    accumulated_questions.extend(path_cursor.qualifying_questions)\n",
    "\n",
    "            # Process each child\n",
    "            for child in children:\n",
    "                prev_questions_str = format_questions_for_prompt(accumulated_questions)\n",
    "\n",
    "                # Generate questions for this child\n",
    "                child_node = current_node.children[child]\n",
    "                child_node.qualifying_questions = question_generator_func(\n",
    "                    child,\n",
    "                    prev_questions_str,\n",
    "                    self.organization\n",
    "                )\n",
    "\n",
    "                # Recursively process this child's children\n",
    "                process_level(current_path + [child])\n",
    "\n",
    "        # Start processing from root\n",
    "        process_level()\n",
    "\n",
    "    def get_questions(self, *path) -> Optional[List[dict]]:\n",
    "        \"\"\"Get qualifying questions for a specific node\"\"\"\n",
    "        node = self.get_section(*path)\n",
    "        return node.qualifying_questions if node else None\n",
    "\n",
    "    def get_questions_with_context(self, *path) -> List[dict]:\n",
    "        \"\"\"Get all questions up to and including this path\"\"\"\n",
    "        questions = []\n",
    "        current_path = []\n",
    "        for section in path:\n",
    "            current_path.append(section)\n",
    "            node = self.get_section(*current_path)\n",
    "            if node and node.qualifying_questions:\n",
    "                questions.extend(node.qualifying_questions)\n",
    "        return questions\n",
    "\n",
    "    def to_jsonl(self, output_file: str) -> None:\n",
    "        \"\"\"Save the policy tree to a JSONL file.\"\"\"\n",
    "        def node_to_dict(node: PolicyNode, doc_title: str, section_path: List[str]) -> dict:\n",
    "            \"\"\"Convert a node to a dictionary format\"\"\"\n",
    "            return {\n",
    "                'document_title': doc_title,\n",
    "                'section_title': ' > '.join(section_path) if section_path else '',\n",
    "                'content': node.raw_content or '',\n",
    "                'labels': node.content_labels or [],\n",
    "                'url': node.url or '',\n",
    "                'qualifying_questions': node.qualifying_questions or []\n",
    "            }\n",
    "\n",
    "        def traverse_tree(node: PolicyNode, doc_title: str = \"\", path: List[str] = None) -> List[dict]:\n",
    "            \"\"\"Traverse the tree and collect all nodes\"\"\"\n",
    "            if path is None:\n",
    "                path = []\n",
    "\n",
    "            items = []\n",
    "\n",
    "            if not doc_title:\n",
    "                for child_title, child_node in node.children.items():\n",
    "                    items.extend(traverse_tree(child_node, child_title))\n",
    "            else:\n",
    "                if node.raw_content or node.qualifying_questions:\n",
    "                    items.append(node_to_dict(node, doc_title, path))\n",
    "\n",
    "                for child_title, child_node in node.children.items():\n",
    "                    items.extend(traverse_tree(child_node, doc_title, path + [child_title]))\n",
    "\n",
    "            return items\n",
    "\n",
    "        items = traverse_tree(self.root)\n",
    "\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            for item in items:\n",
    "                f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8cMPu-jhXbtZ"
   },
   "outputs": [],
   "source": [
    "def clean_markdown(markdown):\n",
    "    \"\"\"\n",
    "    Break policy sections into logically coherent clauses.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    # Instructions\n",
    "    You are given markdown for an expense auditing report. The text for the bullet points is taken verbatim from the policy.\n",
    "    Remove text from the bullet points to make the language more natural in its isolated bullet point form.\n",
    "\n",
    "    Example:\n",
    "    \"In this context, you should submit an explanation document\" -> \"You should submit an explanation document\"\n",
    "\n",
    "    Markdown:\n",
    "    {markdown}\n",
    "\n",
    "    Do not edit the text in any other way.\n",
    "    Respond only with the edited markdown, nothing more.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13KieC60IbAP"
   },
   "source": [
    "# SECTION 4: Retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foA9SRNNH88Z"
   },
   "outputs": [],
   "source": [
    "def extract_titles_subtitles(policy_jsonl_data):\n",
    "    extracted_titles_subtitles = []\n",
    "    i = 0\n",
    "    for record in policy_jsonl_data:\n",
    "        # Remove the 'content' key from the record\n",
    "        filtered_record = {key: value for key, value in record.items() if key != 'content'}\n",
    "        # Remove the 'url' key from the record\n",
    "        url_filtered_record = {key: value for key, value in filtered_record.items() if key != 'url'}\n",
    "        extracted_titles_subtitles.append(url_filtered_record)\n",
    "        i += 1\n",
    "    return extracted_titles_subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2vsvdtuIe9k"
   },
   "outputs": [],
   "source": [
    "# 1-step prompt-based section retrieval based on receipt data\n",
    "def filter_relevant_records(extracted_titles_subtitles, receipt_data, status, organization, location, date):\n",
    "  prompt = f\"\"\"\n",
    "      System information: The user that provided this receipt is a {status} at {organization}, located in {location}, and the current date is {date}.\n",
    "      # Instructions\\n\n",
    "      You are tasked with identifying the relevant sections of an organization's expense policy based on the provided receipt data. Use the following guidelines to filter the records:\\n\n",
    "      1. Analyze the **receipt data** to then compare it with the **titles and section subtitles** of the policy records.\n",
    "      2. Select records that explicitly mention or relate to the details in the receipt, such as:\n",
    "        - Expense category (e.g., meals, lodging, transportation, airfare, gifts, etc.).\n",
    "        - Policy sections that provide relevant guidance for the receipt type or scenario.\n",
    "      3. Ignore records that do not contain information relevant to the receipt's purpose or type. If you are not certain about whether a record is relevant, include it.\n",
    "      4. You must only return the filtered records in the same JSON format.\\n\\n\n",
    "      # Receipt Data\\n\n",
    "      {receipt_data}\n",
    "      # Policy Document, Section Titles and Questions\\n\n",
    "      {extracted_titles_subtitles}\\n\n",
    "      The output must only contain the filtered list of json records of document and section titles.\n",
    "      JSON:\n",
    "      \"\"\"\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "      messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  )\n",
    "\n",
    "  filtered_extracted_titles_subtitles = response.choices[0].message.content\n",
    "  return filtered_extracted_titles_subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7l25E7wIhPP"
   },
   "outputs": [],
   "source": [
    "# 2-step prompt-based section retrieval based on receipt data\n",
    "## 1st step: filter relevant documents given their sections and content summaries\n",
    "def filter_relevant_documents_by_batch(batch_of_document, receipt_data, status, organization, location, date):\n",
    "  prompt = f\"\"\"\n",
    "    # Instructions\n",
    "    You are tasked with determining whether a given policy document is useful for validating compliance of an expense. To make this determination, consider both the provided receipt data and user information, and compare them against the document’s title and its section subtitles. Each subtitle indicates the type of policies contained within that section of the document.\n",
    "\n",
    "    Follow these guidelines:\n",
    "\n",
    "    1. **Analysis of Input:**\n",
    "      - Examine the **Receipt Data** and **User Information** carefully.\n",
    "      - Compare these details to the **Policy Document and Section Titles** you are given.\n",
    "\n",
    "    2. **Criteria for Usefulness:**\n",
    "      - If any of the sections within the document might apply to the expense scenario (e.g., relevant expense category, applicable user context, or timeframe), then the document should be considered useful.\n",
    "      - Answer '<YES>' if you find at least one relevant match between the policy content (as implied by the document and section titles) and the receipt details.\n",
    "      - Answer '<NO>' if none of the information in the document appears relevant. If in doubt, favor '<NO>'.\n",
    "\n",
    "    3. **Justification:**\n",
    "      - Along with the '<YES>' or '<NO>' answer, provide a concise rationale explaining the reasoning behind your decision.\n",
    "      - The reasoning should clarify which elements of the receipt or user profile influenced your decision and how they relate (or do not relate) to the policy document and its section titles.\n",
    "\n",
    "    4. **Formatting the Output:**\n",
    "      - Do not produce code.\n",
    "      - Provide two lines of output:\n",
    "        1. The first line should be either '<YES>' or '<NO>'.\n",
    "        2. The second line should be a brief explanation of why you chose that answer, referencing relevant parts of the receipt and policy document.\n",
    "\n",
    "    # Receipt Data\n",
    "    {receipt_data}\n",
    "\n",
    "    # User Information\n",
    "    The user that provided this receipt is a {status} at {organization}, located in {location}, and the current date is {date}.\n",
    "\n",
    "    # Policy Document and Section Titles\n",
    "    {batch_of_document}\n",
    "\n",
    "    # Final Answer:\n",
    "    <YES or NO> Explanation of the reasoning...\n",
    "    \"\"\"\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "      messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  )\n",
    "\n",
    "  filtered_extracted_titles_subtitles = response.choices[0].message.content\n",
    "  return filtered_extracted_titles_subtitles\n",
    "\n",
    "## 2nd step: filter relevant sections withing a document given their content summary\n",
    "def filter_relevant_sections_by_batch(batch_of_sections, receipt_data, status, organization, location, date):\n",
    "  prompt = f\"\"\"\n",
    "    # Instructions\n",
    "    You are tasked with identifying the relevant sections of an organization's expense policy based on the given receipt data, user information, and policy section titles with their summaries. Your goal is to decide for each policy section whether it should be included for further audit review or not. Follow these guidelines:\n",
    "\n",
    "    1. **Analysis of Input:**\n",
    "      - Consider the **Receipt data** and **User information** as the primary reference.\n",
    "      - Compare these details with the **Policy Document Titles, Section Titles, and Summaries**.\n",
    "\n",
    "    2. **Criteria for Inclusion:**\n",
    "      - Include sections that directly relate to the expense type, category, or scenario indicated by the receipt data.\n",
    "      - Consider aspects like expense category (meals, lodging, transportation, airfare, gifts), user’s role and affiliation, submission date, and any other contextual information from the user profile.\n",
    "      - If uncertain about a section's relevance, err on the side of inclusion.\n",
    "\n",
    "    3. **Exclusion Criteria:**\n",
    "      - Exclude sections that are clearly unrelated to the receipt’s details (e.g., no mentioned expense category, irrelevant policy guidance).\n",
    "\n",
    "    4. **Output Format Requirements:**\n",
    "      - Do not produce code.\n",
    "      - Return the results as a list of objects in valid JSON format.\n",
    "      - Each object should contain:\n",
    "        - 'document_title': The exact document title given.\n",
    "        - 'section_title': The exact section title given.\n",
    "        - 'reasoning': A brief explanation of why this section was included or excluded.\n",
    "        - 'include': 'YES' or 'NO' depending on whether the section is considered relevant.\n",
    "\n",
    "    5. **Formatting:**\n",
    "      - The output must be enclosed in triple backticks as shown below.\n",
    "      - Do not add extra commentary outside the JSON structure.\n",
    "\n",
    "    # Receipt Data\n",
    "    {receipt_data}\n",
    "\n",
    "    # User Information\n",
    "    The user that provided this receipt is a {status} at {organization}, located in {location}, and the current date is {date}.\n",
    "\n",
    "    # Policy Document Titles, Section Titles and Summaries\n",
    "    {batch_of_sections}\n",
    "\n",
    "    # Required JSON output example:\n",
    "    \"\"\" + \"\"\"\n",
    "    ```\n",
    "    [{\n",
    "        \"document_title\": \"\",\n",
    "        \"section_title\": \"\",\n",
    "        \"reasoning\": \"\",\n",
    "        \"include\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"document_title\": \"\",\n",
    "        \"section_title\": \"\",\n",
    "        \"reasoning\": \"\",\n",
    "        \"include\": \"\"\n",
    "    }\n",
    "    ]\n",
    "    ```\n",
    "    # Final Answer:\n",
    "    \"\"\"\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "      messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  )\n",
    "\n",
    "  filtered_extracted_titles_subtitles = response.choices[0].message.content\n",
    "  return filtered_extracted_titles_subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQBvJds-JTLM"
   },
   "outputs": [],
   "source": [
    "# Section retrieval with Ranking LLM (Llama-Rank-V1)\n",
    "def rerank_relevant_records(policy_jsonl, receipt_data, status, organization, location, date):\n",
    "    query = f\"\"\"\n",
    "        System information: The user that provided this receipt is a {status} at {organization}, located in {location}, and the current date is {date}.\n",
    "        # Instructions\\n\n",
    "        You are tasked with identifying the most relevant sections of an organization's expense policy based on the provided receipt data. We want to answer the question: What policies are applicable to this expense? Is this expense compliant or not?\\n\n",
    "        # Receipt Data\\n\n",
    "        {receipt_data}\n",
    "        \"\"\"\n",
    "\n",
    "    documents = policy_jsonl\n",
    "\n",
    "    response = client.rerank.create(\n",
    "        model=\"Salesforce/Llama-Rank-V1\",\n",
    "        query=query,\n",
    "        documents=documents,\n",
    "        return_documents=True,\n",
    "        rank_fields=[\"document_title\", \"section_title\", \"content\"],\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vwf8pp2AJghk"
   },
   "outputs": [],
   "source": [
    "# extract original policy content of filtered sections\n",
    "def extract_relevant_blocks_content_url(filtered_extracted_titles_subtitles, original_records):\n",
    "    \"\"\"\n",
    "    Filters the original records to return the content and URL of records\n",
    "    that match the filtered titles and subtitles.\n",
    "\n",
    "    Args:\n",
    "        filtered_extracted_titles_subtitles (list): Filtered titles and subtitles.\n",
    "        original_records (list): Original records containing content and URLs.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries with matching content and URL.\n",
    "    \"\"\"\n",
    "    # Preprocess the original records into a dictionary for quick lookup\n",
    "    record_map = {\n",
    "        (record.get(\"document_title\"), record.get(\"section_title\")): {\n",
    "            \"document_title\": record.get(\"document_title\"),\n",
    "            \"section_title\": record.get(\"section_title\"),\n",
    "            \"content\": record.get(\"content\"),\n",
    "            \"url\": record.get(\"url\")\n",
    "        }\n",
    "        for record in original_records\n",
    "    }\n",
    "\n",
    "    # Filter the relevant blocks by looking up in the dictionary\n",
    "    relevant_blocks = []\n",
    "    for record in filtered_extracted_titles_subtitles:\n",
    "        key = (record.get(\"document_title\"), record.get(\"section_title\"))\n",
    "        if key in record_map:\n",
    "            relevant_blocks.append(record_map[key])\n",
    "\n",
    "    return relevant_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2x0MWVtKTId"
   },
   "outputs": [],
   "source": [
    "# Extract json type from LLM output string\n",
    "def extract_json_from_llm_output(llm_output):\n",
    "    json_match = re.search(r\"```(.*?)```\", llm_output, re.DOTALL)\n",
    "    if json_match:\n",
    "        json_text = json_match.group(1).strip()  # Extract the JSON text and remove extra whitespace\n",
    "        try:\n",
    "            # Parse the JSON text into a Python list\n",
    "            json_data = json.loads(json_text)\n",
    "            return json_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"No JSON content found between backticks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvf902MYXBKQ"
   },
   "source": [
    "# SECTION 5: Evaluation Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8bfUIqtRUL6"
   },
   "outputs": [],
   "source": [
    "def save_test_to_drive(test, path):\n",
    "    try:\n",
    "        # Check if the file exists in Google Drive\n",
    "        try:\n",
    "            with open(path, 'r') as file:\n",
    "                # Load existing data from the file\n",
    "                data = json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            # Initialize an empty list if the file doesn't exist\n",
    "            data = []\n",
    "\n",
    "        # Append the new test to the list\n",
    "        data.append(test)\n",
    "\n",
    "        # Save the updated data back to the file in Google Drive\n",
    "        with open(path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "        print(f\"Test saved to {path}: {test}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving test: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wP_kd0jFXDv2"
   },
   "outputs": [],
   "source": [
    "def check_clauses_with_LLM(clauses, receipt, organization):\n",
    "    \"\"\"\n",
    "    Batch evaluate multiple policy clauses against a receipt.\n",
    "\n",
    "    Args:\n",
    "        clauses (list): List of clauses to evaluate\n",
    "        receipt (dict): Receipt information\n",
    "        organization (str): Organization name\n",
    "\n",
    "    Returns:\n",
    "        list: List of evaluation results\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    # Instructions\n",
    "    You are helping with expense auditing for {organization}.\n",
    "    You need to evaluate if a receipt meets several policy requirements. Not all requriements are applicable to the expense type or category.\n",
    "    For each requirement, determine:\n",
    "    - 'yes' if the receipt directly meets it\n",
    "    - 'no' if the receipt directly does not meet it\n",
    "    - 'unclear' if you're not certain or missing information\n",
    "    - 'not applicable' if the requirement is not applicable to the expense type or category\n",
    "\n",
    "    Analyze this receipt against the following requirements.\n",
    "    Receipt:\n",
    "    {receipt}\n",
    "\n",
    "    Requirements:\n",
    "    {json.dumps([clause['text'] for clause in clauses], indent=2)}\n",
    "\n",
    "    Return a JSON array with an object for each applicable requirement. Each object should have:\n",
    "    - 'verdict': exactly 'yes', 'no', 'unclear', or 'not applicable'\n",
    "    - 'explanation': brief explanation in 5-10 words\n",
    "\n",
    "    Return only the JSON array, no other text.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "\n",
    "    # Extract and parse JSON array\n",
    "    output = response.choices[0].message.content\n",
    "    array_match = re.search(r'\\[\\s*{.*}\\s*\\]', output, re.DOTALL)\n",
    "    if array_match:\n",
    "        try:\n",
    "            return json.loads(array_match.group())\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: Found array-like structure but couldn't parse as JSON\")\n",
    "            return []\n",
    "    else:\n",
    "        print(\"Error: Couldn't find JSON array in response\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFumn3LxXpR1"
   },
   "outputs": [],
   "source": [
    "def process_multiple_sections(policy_tree, section_paths, organization, receipt):\n",
    "    \"\"\"Process multiple policy sections and combine them into a single report.\"\"\"\n",
    "    print(\"\\n🔍 Starting Policy Analysis...\\n\")\n",
    "\n",
    "    all_items = {\n",
    "        \"Need user detail to determine if valid expense\": [],\n",
    "        \"Required Action\": [],\n",
    "        \"Keep In Mind\": []\n",
    "    }\n",
    "    all_evaluations = []\n",
    "\n",
    "    # Process each section\n",
    "    for section_path in section_paths:\n",
    "        print(f\"📋 Analyzing section: {section_path}\")\n",
    "        path_parts = [part.strip() for part in section_path.split(\">\")]\n",
    "        section_labels = policy_tree.get_labels(*path_parts)\n",
    "        # Filter clauses needing evaluation\n",
    "        need_eval_clauses = [item for item in section_labels\n",
    "                           if item['label'] == \"Need user detail to determine if valid expense\"]\n",
    "\n",
    "        if need_eval_clauses:\n",
    "            print(\"   Evaluating clauses against receipt...\")\n",
    "            evaluations = check_clauses_with_LLM(need_eval_clauses, receipt, organization)\n",
    "\n",
    "            # Match evaluations back to clauses\n",
    "            for clause, evaluation in zip(need_eval_clauses, evaluations):\n",
    "                clause['ai_evaluation'] = evaluation['verdict']\n",
    "                clause['ai_explanation'] = evaluation['explanation']\n",
    "                all_evaluations.append(evaluation['verdict'].lower())\n",
    "\n",
    "        # Process all items including those that don't need evaluation\n",
    "        for item in section_labels:\n",
    "            if item['label'] != \"Need user detail to determine if valid expense\":\n",
    "                item['ai_evaluation'] = None\n",
    "                item['ai_explanation'] = None\n",
    "            item['section_path'] = section_path\n",
    "            all_items[item['label']].append(item)\n",
    "\n",
    "        print(\"   ✓ Section analysis complete\\n\")\n",
    "\n",
    "    # Rest of the function remains the same...\n",
    "    print(\"📊 Determining overall evaluation...\")\n",
    "    overall_eval = None\n",
    "    if all_evaluations:\n",
    "        overall_eval = \"Yes\"\n",
    "        if \"no\" in all_evaluations:\n",
    "            overall_eval = \"No\"\n",
    "        elif \"unclear\" in all_evaluations or \"maybe\" in all_evaluations:\n",
    "            overall_eval = \"Unclear\"\n",
    "\n",
    "    print(\"📝 Formatting final report...\")\n",
    "    markdown = []\n",
    "    markdown.append(f\"#Expense Analysis Report\")\n",
    "    for label in [\"Need user detail to determine if valid expense\",\n",
    "                 \"Required Action\",\n",
    "                 \"Keep In Mind\"]:\n",
    "        if all_items[label]:\n",
    "            if label == \"Need user detail to determine if valid expense\":\n",
    "                markdown.append(f\"##Requirements\")\n",
    "            else:\n",
    "                markdown.append(f\"##{label}\")\n",
    "\n",
    "            current_section = None\n",
    "            for item in sorted(all_items[label], key=lambda x: x['section_path']):\n",
    "                path_parts = [part.strip() for part in item['section_path'].split(\">\")]\n",
    "                url = policy_tree.get_url(*path_parts)\n",
    "\n",
    "                if item['section_path'] != current_section:\n",
    "                    if url:\n",
    "                        markdown.append(f\"\\n###[{path_parts[-1]}]({url})\")\n",
    "                    else:\n",
    "                        markdown.append(f\"\\n###{path_parts[-1]}\")\n",
    "                    current_section = item['section_path']\n",
    "\n",
    "                markdown.append(f\"- {item['text']}\")\n",
    "                if item['ai_evaluation'] is not None:\n",
    "                    markdown.append(f\"  - AI Evaluation: {item['ai_evaluation']}\")\n",
    "                    markdown.append(f\"  - Why? {item['ai_explanation']}\")\n",
    "\n",
    "            if label == \"Need user detail to determine if valid expense\" and overall_eval:\n",
    "                markdown.append(f\"\\n**Overall AI Evaluation: {overall_eval}**\")\n",
    "            markdown.append(\"\")\n",
    "\n",
    "    combined_markdown = \"\\n\".join(markdown)\n",
    "    clean_combined_markdown = clean_markdown(combined_markdown)\n",
    "\n",
    "    print(\"\\n✅ Analysis complete!\\n\")\n",
    "    return clean_combined_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slwTN9fLYPkh"
   },
   "outputs": [],
   "source": [
    "def generate_report(policy_tree, receipt_info, organization, filtered_sections):\n",
    "  final_report = process_multiple_sections(policy_tree, filtered_sections, organization, receipt_info)\n",
    "  display(Markdown(final_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "hMk4nkptRIdB"
   },
   "outputs": [],
   "source": [
    "def fiter_and_retrieve_documents(data, receipt_info, status, organization, location, date):\n",
    "    extracted_titles_subtitles = extract_titles_subtitles(data)\n",
    "\n",
    "    # Group records by 'document_title'\n",
    "    grouped_records = defaultdict(list)\n",
    "\n",
    "    for record in extracted_titles_subtitles:\n",
    "        grouped_records[record['document_title']].append(record)\n",
    "\n",
    "    # Convert to a list of grouped records\n",
    "    batches = list(grouped_records.values())\n",
    "\n",
    "    filtered_batches = []\n",
    "    print(\"🔎 Searching Policy Corpus for relevant documents...\\n   Relevant documents:\\n\")\n",
    "    for batch in batches:\n",
    "      response = filter_relevant_documents_by_batch(batch, receipt_info, status, organization,location, date)\n",
    "      #print(response)\n",
    "      if \"YES\" in response or \"Yes\" in response or \"yes\" in response:\n",
    "          filtered_batches.append(batch)\n",
    "          print(\"   - \" + batch[0]['document_title'])\n",
    "\n",
    "    return filtered_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "p1F2_0NqRL7P"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def fiter_and_retrieve_sections(filtered_batches, receipt_info, status, organization, location, date):\n",
    "    filtered_sections = []\n",
    "\n",
    "    for batch in filtered_batches:\n",
    "        print(f\"🔎 Searching '{batch[0]['document_title']}' for relevant sections...\\n   Relevant sections:\\n\")\n",
    "        while\n",
    "        response = filter_relevant_sections_by_batch(batch, receipt_info, status, organization,location, date)\n",
    "        print(response)\n",
    "        marked_sections_json = extract_json_from_llm_output(response)\n",
    "        for section in marked_sections_json:\n",
    "            if section['include'] == 'yes' or section['include'] == 'Yes' or section['include'] == 'YES':\n",
    "                filtered_sections.append(section)\n",
    "                print(\"   - \" + section['section_title'])\n",
    "\n",
    "    final_sections = []\n",
    "    for section in filtered_sections:\n",
    "        final_sections.append(section['document_title'] + \" > \" + section['section_title'])\n",
    "\n",
    "    return final_sections\n",
    "\"\"\"\n",
    "def fiter_and_retrieve_sections(filtered_batches, receipt_info, status, organization, location, date, chunk_size=20):\n",
    "    filtered_sections = []\n",
    "\n",
    "    for batch in filtered_batches:\n",
    "        # Instead of calling the function on the entire batch at once, break it into chunks\n",
    "        print(f\"🔎 Searching '{batch[0]['document_title']}' for relevant sections...\\n   Relevant sections:\\n\")\n",
    "        chunked_responses = []\n",
    "        for i in range(0, len(batch), chunk_size):\n",
    "            sub_batch = batch[i:i+chunk_size]\n",
    "            #print(f\"🔎 Searching '{sub_batch[0]['document_title']}' for relevant sections (chunk {i//chunk_size + 1})...\\n   Relevant sections:\\n\")\n",
    "            response = filter_relevant_sections_by_batch(sub_batch, receipt_info, status, organization, location, date)\n",
    "            #print(response)\n",
    "\n",
    "            # Extract and append results from this chunk\n",
    "            marked_sections_json = extract_json_from_llm_output(response)\n",
    "            for section in marked_sections_json:\n",
    "                # Normalize the include field to uppercase\n",
    "                include_value = section.get('include', '').strip().upper()\n",
    "                if include_value == 'YES':\n",
    "                    filtered_sections.append(section)\n",
    "                    print(\"   - \" + section['section_title'])\n",
    "\n",
    "    # After processing all batches and sub-batches, collect final sections\n",
    "    final_sections = [\n",
    "        sec['document_title'] + (\" > \" + sec['section_title'] if sec['section_title'].strip() else \"\")\n",
    "        for sec in filtered_sections\n",
    "    ]\n",
    "    return final_sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0pVW9xlIEk5"
   },
   "source": [
    "# SECTION 6: [Do not run] Pre Processing Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "eS-kRinAIHCA",
    "outputId": "003203d1-1cd2-44df-962f-2a32fee18852"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'policy_jsonl_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d7f40e00ab1a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Iterate over records and add summaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpolicy_jsonl_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Process records to replace content with structured clauses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'policy_jsonl_data' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Iterate over records and add summaries\n",
    "for record in policy_jsonl_data:\n",
    "    record['summary'] = summarize_content(record['content'])\n",
    "\n",
    "# Process records to replace content with structured clauses\n",
    "for record in policy_jsonl_data:\n",
    "    record['content'] = analyze_content_to_clauses(record['content'])\n",
    "\n",
    "print(policy_jsonl_data[0])\n",
    "\n",
    "# Specify the path where you want to save the file in your Google Drive\n",
    "file_path = '/content/drive/My Drive/Stanford_Expenses_V1_Pre_Processed.json'\n",
    "\n",
    "# Save the JSON data to the file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(policy_jsonl_data, json_file, indent=4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2uScDe1GyqL"
   },
   "source": [
    "# SECTION 7: Main Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fScjfjoPYZoQ"
   },
   "source": [
    "# [Action item] Run with desired parameters and local file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdhCgfhEYU0J"
   },
   "outputs": [],
   "source": [
    "organization = \"Stanford University\"\n",
    "user_status = \"Student\" # Student, Faculty or Staff\n",
    "organization_location = \"459 Lagunita Dr, Stanford CA 94305\"\n",
    "date = \"12/07/2024\" # Today's date\n",
    "policy_summaries_file_path = '/Stanford_Expenses_V1_Pre_Processed.json'\n",
    "policy_tree_file_path = '/Stanford Policy With Labeled Sections V3.jsonl'\n",
    "receipt_pdf_file_path = '/Uber_Receipt.pdf' # insert receipt pdf file path\n",
    "\n",
    "# Load the preprocessed JSON Policy with summaries\n",
    "with open(policy_summaries_file_path, 'r') as json_file:\n",
    "    policy_jsonl_data = json.load(json_file)\n",
    "\n",
    "# Load pre-processed labeled policies to policy tree\n",
    "with open(policy_tree_file_path, 'r') as f:\n",
    "    items = [json.loads(line) for line in f]\n",
    "policy_tree = PolicyTree(\"Expense Policy\", \"Stanford University\")\n",
    "policy_tree.load_from_jsonl(items)\n",
    "\n",
    "# Extract json receipt data from receipt pdf\n",
    "receipt_info = extract_receipt_info(receipt_pdf_file_path)\n",
    "\n",
    "# Retrieve relevant sections\n",
    "extracted_titles_subtitles_summaries = extract_titles_subtitles(policy_jsonl_data)\n",
    "filtered_documents = fiter_and_retrieve_documents(extracted_titles_subtitles_summaries, receipt_info, user_status, organization, organization_location, date)\n",
    "filtered_sections = fiter_and_retrieve_sections(filtered_documents, receipt_info, user_status, organization, organization_location, date)\n",
    "\n",
    "# Final Evaluation and Report\n",
    "generate_report(policy_tree, receipt_info, organization, filtered_sections)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
